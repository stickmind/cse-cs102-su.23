# UTF-8

C 中的 `char` 是一种单字节数据类型，能够存储 \\(2^8\\) 种不同的位模式。 ASCII 编码标准 (`man ascii`) 为这些模式建立了到各种字母、数字和标点符号的映射，但仅限于 256 个选项，因此仅包含一个子集。 Unicode 是类似 ASCII 的更国际化的编码标准，它定义了一个通用字符集，支持现代和古代多种世界语言的字形（[中文，埃及象形文字，原始表情符号等](http://www.unicode.org/charts/PDF/U13000.pdf)）。然而，如此大量的字符需要一个与单个字符不同的编码系统。对于这部分作业，你将实现最流行的 Unicode 编码 UTF-8，根据[最近的统计](https://w3techs.com/technologies/cross/character_encoding/ranking)，超过 98% 的网站（具有已知的字符编码）都使用该编码！

Unicode 将每个字符映射到一个**码点**（code point），该码点是一个十六进制数字。Unicode 标准中有超过 100 万个不同的码点！字符的码点通常以 `U+NNNN` 格式编写，表示十六进制值 `0xNNNN`。

然而，Unicode 标准没有指定如何以二进制形式最高效地编码这些码点。如何实际存储给定的码点，有多种可能的 Unicode 编码方式。为什么要存在多种编码方式？可能是有不同的优先级，也可能为了与其他非 Unicode 编码兼容，还有其预期的语言环境，空间效率等。根据编码方式的不同，一些问题可能有不同的答案：较小的码点是否应该与较大的码点占用相同的空间量？如果不是，我们如何确定编码的长度？是否可以保持与其他编码（例如 ASCII）的兼容性？

最流行的 Unicode 编码之一是 UTF-8。 UTF-8 之所以流行，部分原因是它保留了与 ASCII 的向后兼容性——事实上，它的设计使 ASCII 成为了 UTF-8 的子集，这意味着 ASCII 编码中表示的字符在 ASCII 和 UTF-8 中具有相同的编码。

UTF-8 编码使用 1 到 4 个字节表示一个码点，具体取决于码点的大小。如果它处在 `U+0000` 到 `U+007F` 范围内，则其 UTF-8 编码长度为 1 个字节。如果它处在 `U+0080` 到 `U+07FF` 范围内，则其 UTF-8 编码长度为 2 个字节。如果它处在 `U+0800` 到 `U+FFFF` 范围内，则其 UTF-8 编码长度为 3 个字节。最后还有一个 4 字节范围，但在本次作业中我们将忽略它。

UTF-8 的工作方式是将码点的二进制表示形式拆分到用于编码的字节中。

- 从 `U+0000` 到 `U+007F` 的码点最多使用 7 位（这些称为“有效位”），编码使用 1 个字节

  其最高有效位为 0，其余位作为 7 个码点有效位。

- 从 `U+0080` 到 `U+07FF` 的码点最多有 11 个有效位，编码使用 2 个字节
  
  第一个字节前缀是 `110`，后面跟着 5 个最高码点有效位；第二个字节前缀是 `10`，后面是其余 6 个码点有效位。

- 从 `U+0800` 到 `U+FFFF` 的码点最多有 16 个有效位，编码使用 3 个字节
  
  第一个字节前缀是 `1110`，后面跟着 4 个最高码点有效位；第二个字节前缀是 `10`，后面跟着 6 个最高码点有效位；第三个字节前缀是 `10`，后面是最后 6 个码点有效位。

下面的表格总结了上面的设计规范。对于每个字节的布局，所有表示形式的 0 和 1 位都是固定的。`xxx` 位存储码点的二进制表示形式。


| Code Point Range     | Significant Bits | UTF-8 Encoded Bytes (Binary) |
| -------------------- | ---------------- | ---------------------------- |
| `U+0000` to `U+007F` | 7                | `0xxxxxxx`                   |
| `U+0080` to `U+07FF` | 11               | `110xxxxx 10xxxxxx`          |
| `U+0800` to `U+FFFF` | 16               | `1110xxxx 10xxxxxx 10xxxxxx` |

如你所见，单字节序列存储码点的 7 位，双字节序列存储 11 位（第一个字节 5 位，另一个字节 6 位），三字节序列存储 16 位（分别存储 4 位、6 位和 6 位）。UTF-8 字节长度取决于存储码点的所有位需要多少字节（1 表示最多 7 个有效位，2 表示最多 11 个有效位，3 表示最多 16 个有效位）。

在单字节序列中，高位始终为 0，其他 7 位是码点本身的值。因此，前 128 个 Unicode 码点与 ASCII 字符使用相同的二进制表示！

对于多字节序列，第一个字节称为**前导字节**（leading byte），后续字节称为**连续字节**（continuation bytes）。前导字节的高位通过 1 的个数表示序列中的总字节数。例如，从 `U+0080` 到 `U+07FF` 的码点编码的前导字节以 `110` 开头，表示整个编码长度为 2 个字节，因为有两个 1。连续字节的高位始终为 `10`。然后将码点的二进制表示划分到前导字节和连续字节的低位。

以下编码过程摘自[维基百科 UTF-8 英文页面](https://en.wikipedia.org/wiki/UTF-8)：

- 考虑对欧元符号 `€` 进行编码，其 Unicode 码点是 `U+20AC`。
- 码点在 `U+0800` 到 `U+FFFF` 范围内，所以需要三个字节来存储。`0x20AC` 的二进制表示有 14 个有效位。
- 前导补充两个 0 后，`0x20AC` 的二进制形式是 `00100000 10101100`。
- 我们来计算 UTF-8 编码的前导字节。高位是固定的 `1110`，表示三字节序列。低位存储码点的 4 个最高位。该字节最终形式为 `11100010`。码点还有 12 位需要编码。
- 接下来，我们来计算第一个连续字节。高位固定为 `10`，低位存储码点的接下来的 6 位。该字节是 `10000010`。码点还有 6 位需要编码。
- 最后，我们来计算最后一个连续字节。高位固定为 `10`，低位存储码点的最后 6 位。这个字节是 `10101100`。
- 由此最终的三字节序列是 `11100010 10000010 10101100`，可以更简洁地写为十六进制，如 `e2 82 ac`。

你的任务是编写 `to_utf8` 函数，该函数接收一个 Unicode 码点并构造出 UTF-8 编码的字节序列。

```c
int to_utf8(unsigned short code_point, unsigned char utf8_bytes[])
```

函数 `to_utf8` 有两个参数；一个 `unsigned short` 类型的 `code_point` 和一个字节数组 `utf8_bytes`。该函数将构造给定码点的 UTF-8 表示形式，并将编码字节序列写入数组 `utf8_bytes` 中。第一个字节（例如前导字节）应位于数组的索引 0 处，其余字节（如果有的话，例如连续字节）应位于索引 1 处，依此类推。`utf8_bytes` 数组由客户端提供，要保证有足够的空间可以容纳完整的 3 个字节，尽管可能只需要 1 或 2 个字节。后续课程会更深入讨论 C 数组，如果你传递一个数组作为参数，修改该数组的元素将修改原始数组，类似 C++ 中的引用参数，因此上面的函数可以传回它创建的字节。该函数返回值是编码的字节数（1、2 或 3）。

你将在提供的 `utf8` 程序中实现这个函数，该程序采用一个或多个码点，并使用 `to_utf8` 函数显示每个码点的 UTF-8 十六进制编码和相应的字符字形。以下一个运行示例：

```shell
$ utf8 0x41 0xfc 0x3c0 0x4751
U+0041   UTF-8 Hex: 41         Character: A  
U+00FC   UTF-8 Hex: c3 bc      Character: ü  
U+03C0   UTF-8 Hex: cf 80      Character: π  
U+4751   UTF-8 Hex: e4 9d 91   Character: 䝑
```

此任务通过提取/重排/打包位模式，是构造位掩码并应用位运算的一个极好实践。
